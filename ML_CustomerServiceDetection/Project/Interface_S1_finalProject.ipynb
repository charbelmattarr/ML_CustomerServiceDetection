{"cells":[{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6912,"status":"ok","timestamp":1710641751754,"user":{"displayName":"Charbel Mattar","userId":"03753297775160290055"},"user_tz":-120},"id":"yGav0tBZuGZf","outputId":"883a94ea-b166-47bb-ee50-e5d9936d88e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyngrok\n","  Downloading pyngrok-7.1.5-py3-none-any.whl (22 kB)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n","Installing collected packages: pyngrok\n","Successfully installed pyngrok-7.1.5\n"]}],"source":["!pip install pyngrok"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":375,"status":"ok","timestamp":1710641753935,"user":{"displayName":"Charbel Mattar","userId":"03753297775160290055"},"user_tz":-120},"id":"Btgr70cet2Ca"},"outputs":[],"source":["from flask import Flask\n","from pyngrok import ngrok"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1710641755985,"user":{"displayName":"Charbel Mattar","userId":"03753297775160290055"},"user_tz":-120},"id":"jTe2TiKPt38W"},"outputs":[],"source":["port_no = 5000"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6hnn_Ijwt45l"},"outputs":[],"source":["from flask import Flask, request, jsonify\n","import requests\n","from PIL import Image\n","import base64\n","import torch\n","from transformers import DetrForObjectDetection, DetrImageProcessor, AutoImageProcessor, AutoModelForImageClassification\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","from io import BytesIO\n","import io\n","\n","app = Flask(__name__)\n","ngrok.set_auth_token(\"2dnR9cObpNxE807tfn8rwWJip20_3vC3MByiiEwSzdZ591TW9\")\n","public_url =  ngrok.connect(port_no).public_url\n","\n","@app.route(\"/\")\n","def home():\n","    return \"\"\"\n","   <!DOCTYPE html>\n","<html lang=\"en\">\n","<head>\n","    <meta charset=\"UTF-8\">\n","    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n","    <title>Your Project Homepage</title>\n","    <style>\n","        /* Basic styling */\n","        body {\n","            font-family: Arial, sans-serif;\n","            background-color: #f9f9f9;\n","            margin: 0;\n","            padding: 0;\n","        }\n","\n","        .header {\n","            background-color: #333;\n","            color: #fff;\n","            padding: 1rem;\n","            text-align: center;\n","        }\n","\n","        .logo {\n","            font-size: 1.5rem;\n","            text-decoration: none;\n","            color: #fff;\n","        }\n","\n","        .nav-items a {\n","            color: #fff;\n","            text-decoration: none;\n","            margin-right: 1rem;\n","        }\n","\n","        .intro {\n","            text-align: center;\n","            padding: 2rem;\n","            background-color: #fff;\n","            border-radius: 10px;\n","            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);\n","        }\n","\n","        h1 {\n","            font-size: 2rem;\n","            margin-bottom: 1rem;\n","        }\n","\n","        p {\n","            font-size: 1rem;\n","            color: #777;\n","        }\n","\n","        button {\n","            background-color: #333;\n","            color: #fff;\n","            border: none;\n","            padding: 0.5rem 1rem;\n","            cursor: pointer;\n","            border-radius: 5px;\n","        }\n","\n","        footer {\n","            background-color: #333;\n","            color: #fff;\n","            text-align: center;\n","            padding: 1rem;\n","        }\n","\n","        .social-media a {\n","            color: #fff;\n","            margin: 0 0.5rem;\n","            font-size: 1.5rem;\n","        }\n","\n","        /* Additional styling for images */\n","        .image-container {\n","            display: flex;\n","            justify-content: center;\n","            margin-top: 2rem;\n","        }\n","\n","        .image-container img {\n","            width: 300px;\n","            height: auto;\n","            margin: 0 1rem;\n","            cursor: pointer;\n","            transition: transform 0.3s ease;\n","        }\n","\n","        .image-container img:hover {\n","            transform: scale(1.1);\n","        }\n","\n","        /* Loader styling */\n","        .loader {\n","            border: 8px solid #f3f3f3; /* Light grey */\n","            border-top: 8px solid #3498db; /* Blue */\n","            border-radius: 50%;\n","            width: 50px;\n","            height: 50px;\n","            animation: spin 2s linear infinite;\n","            display: none; /* Initially hidden */\n","            position: fixed;\n","            top: 50%;\n","            left: 50%;\n","            transform: translate(-50%, -50%);\n","        }\n","\n","        @keyframes spin {\n","            0% { transform: rotate(0deg); }\n","            100% { transform: rotate(360deg); }\n","        }\n","        button.predict-btn:hover {\n","            background-color: #2980b9;\n","        }\n","       /* Predict button styling */\n","        .predict-btn-container {\n","            display: flex;\n","            justify-content: center;\n","            margin-top: 1rem;\n","        }\n","\n","        .predict-btn:hover {\n","            background-color: #2980b9;\n","        }\n","\n","        .predict-btn {\n","            background-color: #3498db;\n","            color: #fff;\n","            border: none;\n","            padding: 0.5rem 1rem;\n","            cursor: pointer;\n","            border-radius: 5px;\n","            font-size: 1rem;\n","            transition: background-color 0.3s ease;\n","        }\n","\n","        .file-input {\n","            display: none;\n","        }\n","    </style>\n","</head>\n","<body>\n","    <header class=\"header\">\n","        <a href=\"#\" class=\"logo\">Emotion Detection</a>\n","        <nav class=\"nav-items\">\n","            <a href=\"#\">Home</a>\n","            <a href=\"#\">About</a>\n","            <a href=\"#\">Contact</a>\n","        </nav>\n","    </header>\n","\n","    <main>\n","        <div class=\"intro\">\n","            <h1>Emotion Detection</h1>\n","            <p>This project aims to detect emotions in images using advanced machine learning models. Simply upload an image, and our system will emotions, and display the results in real-time.</p>\n","\n","            <div class=\"predict-btn-container\">\n","            <button class=\"predict-btn\" onclick=\"predict()\">Predict</button>\n","        </div>\n","        </div>\n","\n","        <div class=\"image-container\">\n","            <img id=\"selectedImage1\" src=\"https://mdbootstrap.com/img/Photos/Others/placeholder.jpg\" alt=\"example placeholder\" onclick=\"document.getElementById('customFile1').click()\">\n","             <div></div>\n","            <img id=\"selectedImage2\" src=\"https://mdbootstrap.com/img/Photos/Others/placeholder.jpg\" alt=\"example placeholder\" onclick=\"document.getElementById('customFile2').click()\">\n","        </div>\n","\n","\n","\n","        <input type=\"file\" class=\"file-input\" id=\"customFile1\" onchange=\"displaySelectedImage(event, 'selectedImage1')\">\n","        <input type=\"file\" class=\"file-input\" id=\"customFile2\" onchange=\"displaySelectedImage(event, 'selectedImage2')\">\n","\n","        <div id=\"loader\" class=\"loader\"></div>\n","    </main>\n","\n","    <footer>\n","        <p>&copy; 2024 Your Project. All rights reserved.</p>\n","        <div class=\"social-media\">\n","            <a href=\"#\"><i class=\"fab fa-facebook\"></i></a>\n","            <a href=\"#\"><i class=\"fab fa-twitter\"></i></a>\n","            <a href=\"#\"><i class=\"fab fa-linkedin\"></i></a>\n","        </div>\n","    </footer>\n","\n","    <script>\n","        function displaySelectedImage(event, elementId) {\n","            const selectedImage = document.getElementById(elementId);\n","            const fileInput = event.target;\n","\n","            if (fileInput.files && fileInput.files[0]) {\n","                const reader = new FileReader();\n","\n","                reader.onload = function(e) {\n","                    selectedImage.src = e.target.result;\n","                };\n","\n","                reader.readAsDataURL(fileInput.files[0]);\n","            }\n","        }\n","\n","        async function predict() {\n","            // Show loader\n","            showLoader();\n","\n","            try {\n","                const selectedImage1 = document.getElementById('selectedImage1');\n","                const imageData = selectedImage1.src.split(',')[1]; // Extract base64-encoded image data\n","\n","                const response = await fetch('/predict', {\n","                    method: 'POST',\n","                    headers: {\n","                        'Content-Type': 'application/json'\n","                    },\n","                    body: JSON.stringify({ image1: imageData })\n","                });\n","\n","                if (!response.ok) {\n","                    throw new Error('Failed to predict');\n","                }\n","\n","                const data = await response.json();\n","\n","                // Update the src attribute of the second image element\n","                const selectedImage2 = document.getElementById('selectedImage2');\n","                selectedImage2.src = 'data:image;base64,' + data.image2;\n","\n","                // Hide loader\n","                hideLoader();\n","            } catch (error) {\n","                console.error('Prediction error:', error);\n","                // Handle error\n","                // Hide loader\n","                hideLoader();\n","            }\n","        }\n","\n","        function showLoader() {\n","            // Show loader element\n","            const loader = document.getElementById('loader');\n","            loader.style.display = 'block';\n","        }\n","\n","        function hideLoader() {\n","            // Hide loader element\n","            const loader = document.getElementById('loader');\n","            loader.style.display = 'none';\n","        }\n","    </script>\n","</body>\n","</html>\n","\n","    \"\"\"\n","\n","def predict_emotions(image_base64):\n","    try:\n","        image_data = base64.b64decode(image_base64)\n","        image = Image.open(BytesIO(image_data))\n","\n","\n","        object_detection_processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\", revision=\"no_timm\")\n","        object_detection_model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\", revision=\"no_timm\")\n","\n","\n","        inputs = object_detection_processor(images=image, return_tensors=\"pt\")\n","        object_outputs = object_detection_model(**inputs)\n","\n","\n","        target_sizes = torch.tensor([image.size[::-1]])\n","        object_results = object_detection_processor.post_process_object_detection(object_outputs, target_sizes=target_sizes, threshold=0.9)[0]\n","\n","\n","        model_path = \"/content/drive/MyDrive/CharbelMATTAR_LU_WebDev/Project/Model\"\n","        emotion_processor = AutoImageProcessor.from_pretrained(model_path)\n","        model_path = \"/content/drive/MyDrive/CharbelMATTAR_LU_WebDev/Project/Model\"\n","        emotion_model = AutoModelForImageClassification.from_pretrained(model_path)\n","\n","\n","        person_counter = 0\n","\n","\n","        fig, ax = plt.subplots(1)\n","        ax.imshow(image)\n","\n","        for score, label, box in zip(object_results[\"scores\"], object_results[\"labels\"], object_results[\"boxes\"]):\n","            box = [round(i, 2) for i in box.tolist()]\n","            class_name = object_detection_model.config.id2label[label.item()]\n","            if class_name == \"person\":\n","                person_counter += 1\n","\n","                roi = image.crop((box[0], box[1], box[2], box[3]))\n","\n","                emotion_inputs = emotion_processor(roi, return_tensors=\"pt\")\n","\n","                emotion_outputs = emotion_model(**emotion_inputs)\n","\n","                predicted_probabilities = torch.softmax(emotion_outputs.logits, dim=1)\n","\n","                predicted_emotion_index = torch.argmax(predicted_probabilities, dim=1)\n","                predicted_emotion_class = predicted_emotion_index.item()\n","\n","                emotion_labels = ['Ahegao', 'Angry', 'Happy', 'Neutral', 'Sad', 'Surprise']\n","                predicted_emotion = emotion_labels[predicted_emotion_class]\n","\n","                label_string = f\"Person {person_counter}: {round(score.item(), 3)}, Emotion: {predicted_emotion}\"\n","\n","                rect = patches.Rectangle((box[0], box[1]), box[2] - box[0], box[3] - box[1],\n","                                         linewidth=1, edgecolor='blue', facecolor='none')\n","                ax.add_patch(rect)\n","                ax.text(box[0], box[1] - 5, label_string, color='blue')\n","            elif class_name == \"cell phone\":\n","                label_string = f\"{class_name}: {round(score.item(), 3)}\"\n","\n","                ax.text(box[0], box[1] - 5, label_string, color='green')\n","\n","\n","        plt.axis('off')\n","        plt.tight_layout()\n","\n","\n","        output_image_buffer = BytesIO()\n","        plt.savefig(output_image_buffer, format='png', bbox_inches='tight', pad_inches=0)  # Save with tight bounding box\n","        output_image_buffer.seek(0)\n","\n","        # Convert the image buffer to base64 string\n","        output_image_base64 = base64.b64encode(output_image_buffer.getvalue()).decode('utf-8')\n","\n","        return output_image_base64\n","\n","\n","\n","    except Exception as e:\n","        print(\"Error:\", str(e))\n","        return None\n","\n","@app.route('/predict', methods=['POST'])\n","def predict():\n","    try:\n","        # Retrieve image data from the request\n","        image_base64 = request.json['image1']\n","\n","\n","        predicted_image = predict_emotions(image_base64)\n","\n","        if predicted_image:\n","            print('222')\n","            # Decode the predicted image from base64\n","            predicted_image_bytes = base64.b64decode(predicted_image)\n","            predicted_image = Image.open(BytesIO(predicted_image_bytes))\n","\n","            plt.imshow(predicted_image)\n","            plt.axis('off')\n","            plt.tight_layout()\n","            plt.show()\n","\n","\n","            predicted_image_base64 = base64.b64encode(predicted_image_bytes).decode('utf-8')\n","\n","        if predicted_image:\n","            return jsonify({'image2': predicted_image_base64})\n","        else:\n","            return jsonify({'error': 'Failed to predict'})\n","\n","    except Exception as e:\n","        return jsonify({'error': str(e)})\n","\n","\n","\n","print(f\"To acces the Gloable link please click {public_url}\")\n","\n","app.run(port=port_no)"]},{"cell_type":"code","source":[],"metadata":{"id":"YY6tplsOHWWq"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOHCE5pytJ20yrQ4KaYeu/7"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}